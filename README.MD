# LocAI - Your AI, Locked and Loaded

![LocAI Logo](public/locai-logo.png)

**LocAI** ist eine moderne Anwendung fÃ¼r lokale KI-UnterstÃ¼tzung, die deine KI-Modelle direkt auf deiner Hardware laufen lÃ¤sst - ohne Cloud-AbhÃ¤ngigkeit, mit voller Kontrolle Ã¼ber deine Daten und maximaler PrivatsphÃ¤re.

> ğŸ”’ **Future Unleashed on Bare Metal** - Leistungsstarke KI-Funktionen, die vollstÃ¤ndig lokal ausgefÃ¼hrt werden.

## ğŸŒŸ Hauptfunktionen

### ğŸ’¬ Lokaler Chat mit verschiedenen Modellen
- **Modellauswahl**: Verwende verschiedene Modelle wie Llama3, Gemma, Mistral oder DeepSeek
- **Anpassbare Prompts**: Passe die Systemanweisungen individuell an deine BedÃ¼rfnisse an
- **Thinking Process**: Beobachte, wie die KI ihre Antworten entwickelt (mit Animation)
- **Mehrfacher Modellwechsel**: Wechsle zwischen Modellen innerhalb einer Konversation

### ğŸ–¼ï¸ Bildanalyse und Vision-Modelle
- **Bildupload**: Lade Bilder hoch und lasse sie von Vision-Modellen analysieren
- **Bild-Text-Kombinationen**: Stelle Fragen zu deinen Bildern
- **Automatische Modellerkennung**: Das System wechselt automatisch zu Vision-Modellen, wenn Bilder erkannt werden

### ğŸ’¾ Lokale Datenspeicherung
- **Speichern von Konversationen**: Speichere deine Chats lokal
- **Export/Import**: Exportiere und importiere Konversationen als JSON-Dateien
- **Bildkomprimierung**: Automatische Optimierung von Bildern fÃ¼r effizienten Speicherplatz

### ğŸ¨ Moderne BenutzeroberflÃ¤che
- **Dark/Light Mode**: WÃ¤hle zwischen hellem und dunklem Design
- **Responsive Design**: Optimiert fÃ¼r Desktop und mobile GerÃ¤te
- **Intuitive Bedienung**: Benutzerfreundliche OberflÃ¤che mit klaren Funktionen

## ğŸš€ Erste Schritte

### Voraussetzungen
- [Node.js](https://nodejs.org/) (Version 18 oder hÃ¶her)
- [Ollama](https://ollama.ai/) fÃ¼r die lokale AusfÃ¼hrung von KI-Modellen
- Ein oder mehrere KI-Modelle Ã¼ber Ollama installiert (z.B. llama3, llama3.2-vision)

### Installation

1. Repository klonen
   ```bash
   git clone https://github.com/yourusername/locai.git
   cd locai
   ```

2. AbhÃ¤ngigkeiten installieren
   ```bash
   npm install
   ```

3. Entwicklungsserver starten
   ```bash
   npm run dev
   ```

4. Ollama-Modelle installieren (falls noch nicht vorhanden)
   ```bash
   ollama pull llama3
   ollama pull llama3.2-vision
   ```

## ğŸ“š Verwendung

### Chat-Funktion
1. WÃ¤hle ein Modell aus dem Dropdown-MenÃ¼
2. Gib deine Nachricht ein und sende sie
3. Die KI prÃ¤sentiert ihren Denkprozess und generiert eine Antwort
4. Speichere interessante Konversationen mit dem Speichern-Button

### Bildanalyse
1. Klicke auf das Kamera-Symbol neben dem Texteingabefeld
2. WÃ¤hle ein oder mehrere Bilder aus
3. Optional: FÃ¼ge eine Beschreibung oder Frage zum Bild hinzu
4. Sende die Nachricht - die App wechselt automatisch zu einem Vision-Modell

### Konversationen verwalten
1. Speichere Konversationen Ã¼ber den "Speichern"-Button
2. Greife auf gespeicherte Konversationen Ã¼ber die Seitenleiste oder das "Laden"-Dropdown zu
3. Exportiere deine Konversationen als JSON-Dateien zur Sicherung
4. Importiere zuvor exportierte Konversationen

## ğŸ”§ Technische Details

### Architektur
- **Next.js**: Frontend-Framework fÃ¼r reaktive BenutzeroberflÃ¤chen
- **TypeScript**: Typsicherheit und verbesserte Entwicklererfahrung
- **Ollama API**: Lokale Schnittstelle zu den KI-Modellen
- **LocalStorage/FileSystem**: Lokale Datenpersistenz ohne DatenbankabhÃ¤ngigkeit

### Anpassung
Die Anwendung ist modular aufgebaut und kann leicht erweitert werden:
- **Neue Modelle**: UnterstÃ¼tzt neue Modelle durch HinzufÃ¼gen entsprechender Templates
- **Weitere Funktionen**: Erweiterbar durch modulare Komponenten

## ğŸ” Datenschutz

LocAI wurde mit Fokus auf Datenschutz und Sicherheit entwickelt:
- **Keine Cloudspeicherung**: Alle Daten bleiben auf deinem GerÃ¤t
- **Keine Telemetrie**: Keine DatenÃ¼bertragung an externe Server
- **Exportierbare Daten**: Volle Kontrolle Ã¼ber deine Daten

## ğŸ› ï¸ Contributing

BeitrÃ¤ge zum Projekt sind willkommen! Beachte bitte die folgenden Schritte:
1. Fork das Repository
2. Erstelle einen Feature-Branch (`git checkout -b feature/amazing-feature`)
3. Committe deine Ã„nderungen (`git commit -m 'Add some amazing feature'`)
4. Push den Branch (`git push origin feature/amazing-feature`)
5. ErÃ¶ffne einen Pull Request

## ğŸ“ Lizenz

Dieses Projekt ist unter der MIT-Lizenz lizenziert - siehe die LICENSE-Datei fÃ¼r Details.

Creator:
```plaintext
-+=--+=--+=--+=--+=--+=--+=--+=--+=--+=--+=--+=--+=--+=--+=--+=-
  ##     ##            ###       ###  ##    ##   ########  ########
  ###   ###            ####     ####  ##    ##   ########  ########     
  ## # # ##            ## ##  ##  ##  ##    ##   ##        ##     
  ##  #  ##    #####   ##  ## ##  ##  ##    ##   ##        ##     
  ##     ##   ##       ##    %    ##  ##    ##   ######    ###### 
  ##     ##  ##        ##         ##  ##    ##   ######    ######     
  ##     ##  ##        ##         ##  ##    ##   ##        ##     
  ##     ##   ##       ##         ##  ##    ##   ##        ##     
  ##     ##    #####   ##         ##  ########   ##        ##     
-+=--+=--+=--+=--+=--+=--+=--+=--+=--+=--+=--+=--+=--+=--+=--+=-
```
---

## ğŸ™ Danksagungen

- [Ollama](https://ollama.ai/) fÃ¼r die lokale KI-ModellunterstÃ¼tzung
- [Next.js](https://nextjs.org/) fÃ¼r das reaktive Frontend-Framework
- [Shadcn/UI](https://ui.shadcn.com/) fÃ¼r die schÃ¶nen UI-Komponenten 
